{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roquero/miniconda3/lib/python3.7/site-packages/matplotlib/__init__.py:886: MatplotlibDeprecationWarning: \n",
      "examples.directory is deprecated; in the future, examples will be found relative to the 'datapath' directory.\n",
      "  \"found relative to the 'datapath' directory.\".format(key))\n"
     ]
    }
   ],
   "source": [
    "import sys, os, itertools, sklearn\n",
    "sys.path.append('/home/roquero/CausalAggregation/Code')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import _pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LassoCV, Lasso\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import auc\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "np.set_printoptions(suppress=True)\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)}, linewidth=100000)\n",
    "from backfitting import Backfitting\n",
    "from base_environment import BaseEnvironment\n",
    "from collection_environment import CollectionEnvironment\n",
    "from regression_method import PolynomialRegression, RandomForestRegression\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ik_h, se_h = [], (lambda input_samples:input_samples)\n",
    "ik_x1, se_x1 = ['h'], (lambda input_samples: 2*input_samples[0] + input_samples[1])\n",
    "ik_x2, se_x2 = ['h', 'x1'], (lambda input_samples: input_samples[0] + input_samples[1] + input_samples[2])\n",
    "ik_x3, se_x3 = ['x1', 'x2'], (lambda input_samples: -input_samples[0] * 2*input_samples[1] + input_samples[2])\n",
    "ik_x4, se_x4 = ['x1', 'x3'], (lambda input_samples: np.log(1+np.abs(input_samples[0])) + input_samples[1] + input_samples[2])\n",
    "\n",
    "ik_y, se_y = ['h','x1','x2','x3','x4'], (lambda input_samples:\n",
    "                                         0*input_samples[0] \n",
    "                                         + 1*input_samples[1]**2\n",
    "                                         #- 0.5*input_samples[3]*input_samples[4]\n",
    "                                         - 1*input_samples[2]*input_samples[4] + 0.3*input_samples[5])\n",
    "ik_x5, se_x5 = ['x2', 'x4', 'y'], (lambda input_samples: 2*input_samples[0] + input_samples[1] - input_samples[2] + input_samples[3])\n",
    "\n",
    "fh = {'input_keys':ik_h, 'structural_eq': se_h}\n",
    "f1 = {'input_keys':ik_x1, 'structural_eq': se_x1}\n",
    "f2 = {'input_keys':ik_x2, 'structural_eq': se_x2}\n",
    "f3 = {'input_keys':ik_x3, 'structural_eq': se_x3}\n",
    "f4 = {'input_keys':ik_x4, 'structural_eq': se_x4}\n",
    "f5 = {'input_keys':ik_x5, 'structural_eq': se_x5}\n",
    "fy = {'input_keys':ik_y, 'structural_eq': se_y}\n",
    "\n",
    "sh = lambda n_samples: np.random.normal(size=n_samples)\n",
    "s1 = lambda n_samples: np.random.normal(size=n_samples)\n",
    "s2 = lambda n_samples: np.random.normal(size=n_samples)\n",
    "s3 = lambda n_samples: np.random.normal(size=n_samples)\n",
    "s4 = lambda n_samples: np.random.normal(size=n_samples)\n",
    "s5 = lambda n_samples: np.random.normal(size=n_samples)\n",
    "sy = lambda n_samples: np.random.normal(size=n_samples)\n",
    "\n",
    "topo_order = ['h','x1','x2','x3','x4','y','x5']\n",
    "y_key = 'y'\n",
    "x_key = ['x1','x2','x3','x4','x5']\n",
    "\n",
    "structural_equation_dict = {'x1':f1, 'x2':f2, 'x3':f3, 'y':fy, 'x4':f4, 'x5':f5, 'h':fh}\n",
    "disturbance_sampler_dict = {'x1':s1, 'x2':s2, 'x3':s3, 'y':sy, 'x4':s4, 'x5':s5, 'h':sh}\n",
    "\n",
    "base = BaseEnvironment(structural_equation_dict, disturbance_sampler_dict, topo_order, y_key, x_key)\n",
    "coll_env = CollectionEnvironment(base)\n",
    "\n",
    "params_method = {'regression_method':'HuberRegressor',\n",
    "                 'power_features': {\n",
    "                     'e1':2,\n",
    "                     'e2':2,\n",
    "                     'e3':2,\n",
    "                     'e4':2,\n",
    "                     'e5':2,\n",
    "                                     },\n",
    "                 'selected_features':{\n",
    "                     'e1':['1','x1^0', 'x2^0','x2^2',  'x3^0', 'x1^2', 'x1^0x2^0', 'x1^0x3^0',  'x2^0x3^0', 'x3^2'],\n",
    "                     'e2':['x2^0x4^0'],\n",
    "                     'e3':['x3^0x4^0'],\n",
    "                     'e4':['x1^0x5^0'],\n",
    "                 },\n",
    "                }\n",
    "\n",
    "backfit = Backfitting(PolynomialRegression, \n",
    "                  'boosting',\n",
    "                  max_n_iter=20,\n",
    "                  gap_convergence=1e-5,\n",
    "                  warm_start=False, \n",
    "                  params_method=params_method,\n",
    "                  reweighting_candidates=True,\n",
    "                  update_within_loop=False,\n",
    "                  true_y_coeff={'x1^2':0.5, 'x1^0x2^0':-0.5, 'x1^0x2^0x3^0':0.05, 'x3^0x4^0':-0.5, 'x2^0x4^0':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples_list = [100,200,500,1000,2000,5000,10000]\n",
    "loss_mean_list, loss_std_list, naive_loss_mean_list, naive_loss_std_list = [], [], [], []\n",
    "\n",
    "for n_samples in n_samples_list:\n",
    "    loss_list=[]\n",
    "    naive_loss_list=[]\n",
    "    n_rep=10\n",
    "    for i in np.arange(n_rep):\n",
    "        coll_env.reset_env()\n",
    "        coll_env.add_env('e1', {'x1':{'type':'independent'},'x2':{'type':'independent'}, 'x3':{'type':'independent'}}, n_samples)\n",
    "        coll_env.add_env('e2', {'x2':{'type':'independent'},'x4':{'type':'independent'}}, n_samples)\n",
    "        coll_env.add_env('e3', {'x4':{'type':'independent'},'x3':{'type':'independent'}}, n_samples)\n",
    "        coll_env.add_env('e4', {'x1':{'type':'independent'},'x5':{'type':'independent'}}, n_samples)\n",
    "              \n",
    "        try:\n",
    "            loss_list.append(backfit.fitCV(coll_env))\n",
    "            #naive_loss_list.append(backfit.fit_naiveCV(coll_env))   \n",
    "        except:\n",
    "            pass\n",
    "    loss_mean_list.append(np.mean(np.stack(loss_list)[:,1]))\n",
    "    loss_std_list.append(np.std(np.stack(loss_list)[:,1]))\n",
    "    #naive_loss_mean_list.append(np.mean(np.stack(naive_loss_list)[:,1]))\n",
    "    #naive_loss_std_list.append(np.std(np.stack(naive_loss_list)[:,1]))\n",
    "print(loss_mean_list, loss_std_list, naive_loss_mean_list, naive_loss_std_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Backfitting' object has no attribute 'x_train_full'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-1d0bac69aff0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m                 \u001b[0mdegree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                 )\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackfit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_train_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLasso\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackfit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_train_full\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Backfitting' object has no attribute 'x_train_full'"
     ]
    }
   ],
   "source": [
    "poly = PolynomialFeatures(\n",
    "                degree=2\n",
    "                )\n",
    "x = poly.fit_transform(backfit.x_train_full.T)\n",
    "lr = Lasso(alpha=0.01)\n",
    "lr.fit(x, backfit.y_train_full)\n",
    "np.mean(np.square(lr.predict(poly.fit_transform(backfit.x_val_full.T))-backfit.true_function_y(backfit.x_val_full)))\n",
    "np.mean(np.square(lr.predict(poly.fit_transform(backfit.x_val_full.T))-backfit.y_val_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11085.574467284046, 11086.519498889349)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples=5000\n",
    "\n",
    "coll_env.reset_env()\n",
    "coll_env.add_env('e1', {'x1':{'type':'independent'},'x2':{'type':'independent'}, 'x3':{'type':'independent'}}, n_samples)\n",
    "coll_env.add_env('e2', {'x2':{'type':'independent'},'x4':{'type':'independent'}}, n_samples)\n",
    "coll_env.add_env('e3', {'x4':{'type':'independent'},'x3':{'type':'independent'}}, n_samples)\n",
    "coll_env.add_env('e4', {'x1':{'type':'independent'},'x5':{'type':'independent'}}, n_samples)\n",
    "\n",
    "backfit.fitCV(coll_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
