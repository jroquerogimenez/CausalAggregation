{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roquero/miniconda3/lib/python3.7/site-packages/matplotlib/__init__.py:886: MatplotlibDeprecationWarning: \n",
      "examples.directory is deprecated; in the future, examples will be found relative to the 'datapath' directory.\n",
      "  \"found relative to the 'datapath' directory.\".format(key))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression, LassoCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import itertools\n",
    "import sys\n",
    "sys.path.append('/home/roquero/CausalAggregation/Code')\n",
    "from generateEnvironment import GenerateEnvironment, generate_constraints\n",
    "from gmm_estimator import SolveProblem\n",
    "import matplotlib as mpl\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"sans-serif\",\n",
    "    \"font.sans-serif\": [\"Helvetica\"]})\n",
    "np.set_printoptions(suppress=True)\n",
    "np.set_printoptions(precision=5)\n",
    "np.set_printoptions(linewidth=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dim=202\n",
    "y_index=100\n",
    "connectivity_e0 = np.zeros((n_dim,n_dim))\n",
    "z = 2*np.random.binomial(1,0.5, size=n_dim-1)-1\n",
    "connectivity_e0[np.arange(1,n_dim), np.arange(0,n_dim-1)] = np.random.normal(size=(n_dim-1))*0.5 +1\n",
    "connectivity_e0[1,0]=0\n",
    "connectivity_e0[2,0]=1\n",
    "connectivity_e0[y_index,0]=2\n",
    "connectivity_e0[n_dim-1,0]=1\n",
    "\n",
    "x_indices=np.hstack([np.arange(1,y_index),(np.arange(y_index+1,n_dim))])\n",
    "n_reps=50\n",
    "alpha=0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_samples 100: Avg coverage: 0.9926470588235294 pm0.02416423047816909. Avg length: 531.0018707904289 pm1303.0086065765104. Avg selected: 2.72 pm0.2594763958436297.\n",
      "For n_samples 200: Avg coverage: 0.959731543624161 pm0.0556035306770684. Avg length: 1.0956281225463527 pm0.3371481638748519. Avg selected: 2.98 pm0.2560624923724675.\n",
      "For n_samples 500: Avg coverage: 0.9679144385026738 pm0.049844621166763824. Avg length: 0.5496504173605108 pm0.13788880923586438. Avg selected: 3.74 pm0.16790473489452284.\n",
      "For n_samples 1000: Avg coverage: 0.9617021276595744 pm0.054281595639496076. Avg length: 0.3617865117688198 pm0.07900523547691322. Avg selected: 4.7 pm0.26683328128252665.\n",
      "For n_samples 5000: Avg coverage: 0.939622641509434 pm0.06736879578693253. Avg length: 0.14255487613604517 pm0.02862221056335635. Avg selected: 5.3 pm0.12961481396815722.\n"
     ]
    }
   ],
   "source": [
    "for n_samples in np.array([100,200,500,1000,5000]):\n",
    "    coverage =[]\n",
    "    length = []\n",
    "    num_selected_indices = []\n",
    "    for _ in np.arange(n_reps):\n",
    "        \n",
    "        solver_obs = SolveProblem(connectivity_e0,x_indices,y_index)\n",
    "        obs_dataset = solver_obs.generate_intervention(n_samples, {})['dataset']\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        obs_dataset = scaler.fit_transform(obs_dataset.T).T\n",
    "        select_markov = LassoCV(max_iter=5000)\n",
    "        _ = select_markov.fit(obs_dataset[x_indices,:].T,obs_dataset[y_index,:])\n",
    "        selected_indices = x_indices[np.where(np.abs(select_markov.coef_)>1e-3)[0]]\n",
    "        n_selected_indices = len(set(selected_indices).intersection(set([1,2,99,101,200,201])))\n",
    "\n",
    "        solver = SolveProblem(connectivity_e0,selected_indices,y_index)\n",
    "        list_dict_interventions = [{i:{'type':'independent'} for i in selected_indices[n_selected_indices//2:]},\n",
    "                                  {i:{'type':'independent'} for i in selected_indices[:n_selected_indices//2]}] \n",
    "        #list_dict_interventions = [{i:{'type':'independent'} for i in selected_indices}] \n",
    "        list_environments = [solver.generate_intervention(n_samples, dict_interventions)\n",
    "                             for dict_interventions in list_dict_interventions]\n",
    "        n_samples_tot = np.sum([env['dataset'].shape[1] for env in list_environments])\n",
    "        ### Estimate beta_hat and aCov here\n",
    "    \n",
    "        beta_hat, aCov = solver.compute_beta_GMM(list_environments)\n",
    "\n",
    "        ###\n",
    "    \n",
    "        CI = solver.compute_CI(beta_hat, aCov, n_samples_tot, alpha)\n",
    "        #print(beta_hat, CI, solver.beta)\n",
    "        for coord in np.arange(n_selected_indices):\n",
    "            coverage.append((CI[0,coord]<solver.beta[coord])&\n",
    "                        (CI[1,coord]>solver.beta[coord]))\n",
    "            length.append(CI[1,coord]-CI[0,coord])\n",
    "        num_selected_indices.append(n_selected_indices) \n",
    "    print('For n_samples {}: Avg coverage: {} pm{}. Avg length: {} pm{}. Avg selected: {} pm{}.'.format(n_samples,np.mean(coverage),\n",
    "                                                                                                        2*np.std(coverage)/np.sqrt(n_reps),\n",
    "                                                                                                        np.mean(length),\n",
    "                                                                                                        2*np.std(length)/np.sqrt(n_reps),\n",
    "                                                                                                       np.mean(num_selected_indices),\n",
    "                                                                                                       2*np.std(num_selected_indices)/np.sqrt(n_reps))\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_samples 100: Avg coverage: 0.6702355460385439 pm0.1329721350855009. Avg length: 0.36488433859184 pm0.03318998269387847.\n",
      "For n_samples 200: Avg coverage: 0.6195028680688337 pm0.13732270446603442. Avg length: 0.24285437615444658 pm0.01942379482814677.\n",
      "For n_samples 500: Avg coverage: 0.5255198487712666 pm0.14123703121170217. Avg length: 0.1489905193906185 pm0.01242040478341625.\n",
      "For n_samples 1000: Avg coverage: 0.5473537604456824 pm0.1407856871621978. Avg length: 0.10785139062599561 pm0.0085728260236467.\n",
      "For n_samples 5000: Avg coverage: 0.42543171114599687 pm0.13983978555400775. Avg length: 0.04897066893444497 pm0.003845301282116153.\n"
     ]
    }
   ],
   "source": [
    "for n_samples in np.array([100,200,500,1000,5000]):\n",
    "    coverage=[]\n",
    "    length=[]\n",
    "    num_selected_indices = []\n",
    "    for _ in np.arange(n_reps):\n",
    "        \n",
    "        solver_obs = SolveProblem(connectivity_e0,x_indices,y_index)\n",
    "        obs_dataset = solver_obs.generate_intervention(n_samples, {})['dataset']\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        obs_dataset = scaler.fit_transform(obs_dataset.T).T\n",
    "        select_markov = LassoCV(max_iter=5000)\n",
    "        _ = select_markov.fit(obs_dataset[x_indices,:].T,obs_dataset[y_index,:])\n",
    "        selected_indices = x_indices[np.where(np.abs(select_markov.coef_)>1e-3)[0]]\n",
    "        n_selected_indices = len(selected_indices)\n",
    "        \n",
    "        solver = SolveProblem(connectivity_e0,selected_indices,y_index)\n",
    "        list_dict_interventions = [{i:{'type':'independent'} for i in selected_indices[n_selected_indices//2:]},\n",
    "                                  {i:{'type':'independent'} for i in selected_indices[:n_selected_indices//2]}]       \n",
    "        list_environments = [solver.generate_intervention(n_samples, dict_interventions)\n",
    "                             for dict_interventions in list_dict_interventions]\n",
    "        n_samples_tot = np.sum([env['dataset'].shape[1] for env in list_environments])\n",
    "        ### Estimate beta_hat and aCov here\n",
    "    \n",
    "        beta_hat, aCov = solver.compute_pooled_beta_OLS(list_environments)\n",
    "  \n",
    "        ###\n",
    "    \n",
    "        CI = solver.compute_CI(beta_hat, aCov, n_samples_tot, alpha)\n",
    "        \n",
    "        for coord in np.arange(n_selected_indices):\n",
    "            coverage.append((CI[0,coord]<solver.beta[coord])&\n",
    "                        (CI[1,coord]>solver.beta[coord]))\n",
    "            length.append(CI[1,coord]-CI[0,coord])\n",
    "            \n",
    "    print('For n_samples {}: Avg coverage: {} pm{}. Avg length: {} pm{}.'.format(n_samples,np.mean(coverage),2*np.std(coverage)/np.sqrt(n_reps),np.mean(length),2*np.std(length)/np.sqrt(n_reps))\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
